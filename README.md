# indrima24
Master's thesis work:
This thesis examines the application of Q-learning in a Reinforcement Learning (RL) frame-work to develop game playing agents for abstract board games With increasing state-space com-plexity. The two aspects that this thesis investigates are, first, training of the Q-learning agent, andsecond, providing a methodology to evaluate a variety of agents.  We focus on agent performancein three games - Tic-Tac-Toe, Nine-Men’s Morris, and Mancala.  Each of these games has an in-creased state-space complexity going from first to last, respectively. However, each of these gameshave been demonstrated to be solved by learning agents.To  train  and  evaluate  our  agents,  we  use  the  Ludii  General  Game  System,  created  by  theDigital Ludeme Project (DLP). To see how the Q-learning based game playing agent trains, thelearning agent plays a particular game against a teaching agent where we test out different RLagents.  The teaching agents include a Q-learning agent,  a deterministic Min-Max agent,  and anon-deterministic Min-Max agent.  We observe the number of training generations needed untilthe learning agent converges as all the games we test, in this thesis, are solved by RL agents.  Werecord this information and provide some insights into training. We find that although Min-Max isthe best teaching agent, but Q-learning allows us to solve the problem without needing an existingagent Additionally, we provide a method to create weaker agents that can be used in a variety ofsituations.For the evaluation of each agent, we make use of a methodology to evaluate a group of agentsplaying the three board games.  This includes a methodology on how to find the number of trialssuch that evaluation of a particular agent is stable.  We use a round-robin tournament where ourselected agents play each other both as first and second players. Additionally, we provide a meansto  determine  how  many  games  are  played  in  each  match.To  quantitatively  assess  which  of  theplayers is the best we use a point system.  Our results show that the deterministic Min-Max agentis the best agent for all three of the games, the fully converged Q-learning based agent is a closesecond for both Tic-Tac-Toe and Nine Men’s Morris, and the non deterministic Min-Max agentcomes in second place for Mancala.
